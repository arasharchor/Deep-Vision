


<!DOCTYPE html>
<html lang="en" class=" is-copy-enabled">
  <head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# object: http://ogp.me/ns/object# article: http://ogp.me/ns/article# profile: http://ogp.me/ns/profile#">
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="Content-Language" content="en">
    <meta name="viewport" content="width=1020">
    
    
    <title>awesome-deep-vision/README.md at master · kjw0612/awesome-deep-vision</title>
    <link rel="search" type="application/opensearchdescription+xml" href="/opensearch.xml" title="GitHub">
    <link rel="fluid-icon" href="https://github.com/fluidicon.png" title="GitHub">
    <link rel="apple-touch-icon" sizes="57x57" href="/apple-touch-icon-114.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/apple-touch-icon-114.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/apple-touch-icon-144.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/apple-touch-icon-144.png">
    <meta property="fb:app_id" content="1401488693436528">

      <meta content="@github" name="twitter:site" /><meta content="summary" name="twitter:card" /><meta content="kjw0612/awesome-deep-vision" name="twitter:title" /><meta content="awesome-deep-vision - A curated list of deep learning resources for computer vision " name="twitter:description" /><meta content="https://avatars1.githubusercontent.com/u/2831504?v=3&amp;s=400" name="twitter:image:src" />
      <meta content="GitHub" property="og:site_name" /><meta content="object" property="og:type" /><meta content="https://avatars1.githubusercontent.com/u/2831504?v=3&amp;s=400" property="og:image" /><meta content="kjw0612/awesome-deep-vision" property="og:title" /><meta content="https://github.com/kjw0612/awesome-deep-vision" property="og:url" /><meta content="awesome-deep-vision - A curated list of deep learning resources for computer vision " property="og:description" />
      <meta name="browser-stats-url" content="https://api.github.com/_private/browser/stats">
    <meta name="browser-errors-url" content="https://api.github.com/_private/browser/errors">
    <link rel="assets" href="https://assets-cdn.github.com/">
    <link rel="web-socket" href="wss://live.github.com/_sockets/MTI5MDMzNjI6NGI4Yjg5NzY2ZjIyNGUyNTBlMTcyZDI5OGU1OGE0MTQ6OGI3NGVhMTRmMmNlZWFhZWQ0ZGFkN2Y3ZDY0ODNjZGMwNmIwYWQxMjhmODY3ZWE0NTA4MGNiNzVmZTk2NmQ1NQ==--b0205bb68933dfc7c4835944d0d8892ef704c524">
    <meta name="pjax-timeout" content="1000">
    <link rel="sudo-modal" href="/sessions/sudo_modal">

    <meta name="msapplication-TileImage" content="/windows-tile.png">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="selected-link" value="repo_source" data-pjax-transient>

    <meta name="google-site-verification" content="KT5gs8h0wvaagLKAVWq8bbeNwnZZK1r1XQysX3xurLU">
        <meta name="google-analytics" content="UA-3769691-2">

    <meta content="collector.githubapp.com" name="octolytics-host" /><meta content="collector-cdn.github.com" name="octolytics-script-host" /><meta content="github" name="octolytics-app-id" /><meta content="866050D3:345E:1AD7CB2:55E23F5D" name="octolytics-dimension-request_id" /><meta content="12903362" name="octolytics-actor-id" /><meta content="smajida" name="octolytics-actor-login" /><meta content="0ec75e893480ab0145778c4325f9ac09e3886301cd4154a023590188f2fdcc7b" name="octolytics-actor-hash" />
    
    <meta content="Rails, view, blob#show" data-pjax-transient="true" name="analytics-event" />
    <meta class="js-ga-set" name="dimension1" content="Logged In">
      <meta class="js-ga-set" name="dimension4" content="Current repo nav">
    <meta name="is-dotcom" content="true">
        <meta name="hostname" content="github.com">
    <meta name="user-login" content="smajida">

      <link rel="icon" sizes="any" mask href="https://assets-cdn.github.com/pinned-octocat.svg">
      <meta name="theme-color" content="#4078c0">
      <link rel="icon" type="image/x-icon" href="https://assets-cdn.github.com/favicon.ico">

    <!-- </textarea> --><!-- '"` --><meta content="authenticity_token" name="csrf-param" />
<meta content="JiyAT3HEosFCFzDIAp2v6sWkoYsSfhAdCf0wTQaOw6Vp5om0fsBRSeCK0gLXZxtFnwQ8V3WqA+boIKLOoIew5w==" name="csrf-token" />
    <meta content="722279213b9f61f1fc9f5f6cc19a8243c427cb59" name="form-nonce" />

    <link crossorigin="anonymous" href="https://assets-cdn.github.com/assets/github/index-ebd09ebc92d1048dd7af5cd68484181a6a6a0260b3df1e7349053db235e6c53a.css" media="all" rel="stylesheet" />
    <link crossorigin="anonymous" href="https://assets-cdn.github.com/assets/github2/index-f20fa2d1dc1467ff8e2f823d0c693c4aba5668d5b740a4c567afc32f85422020.css" media="all" rel="stylesheet" />
    
    


    <meta http-equiv="x-pjax-version" content="58acd2acac42635f7fc990a652c05ff3">

      
  <meta name="description" content="awesome-deep-vision - A curated list of deep learning resources for computer vision ">
  <meta name="go-import" content="github.com/kjw0612/awesome-deep-vision git https://github.com/kjw0612/awesome-deep-vision.git">

  <meta content="2831504" name="octolytics-dimension-user_id" /><meta content="kjw0612" name="octolytics-dimension-user_login" /><meta content="35812923" name="octolytics-dimension-repository_id" /><meta content="kjw0612/awesome-deep-vision" name="octolytics-dimension-repository_nwo" /><meta content="true" name="octolytics-dimension-repository_public" /><meta content="false" name="octolytics-dimension-repository_is_fork" /><meta content="35812923" name="octolytics-dimension-repository_network_root_id" /><meta content="kjw0612/awesome-deep-vision" name="octolytics-dimension-repository_network_root_nwo" />
  <link href="https://github.com/kjw0612/awesome-deep-vision/commits/master.atom" rel="alternate" title="Recent Commits to awesome-deep-vision:master" type="application/atom+xml">

  </head>


  <body class="logged_in  env-production linux vis-public page-blob">
    <a href="#start-of-content" tabindex="1" class="accessibility-aid js-skip-to-content">Skip to content</a>
    <div class="wrapper">
      
      
      



        <div class="header header-logged-in true" role="banner">
  <div class="container clearfix">

    <a class="header-logo-invertocat" href="https://github.com/" data-hotkey="g d" aria-label="Homepage" data-ga-click="Header, go to dashboard, icon:logo">
  <span class="mega-octicon octicon-mark-github"></span>
</a>


      <div class="site-search repo-scope js-site-search" role="search">
          <!-- </textarea> --><!-- '"` --><form accept-charset="UTF-8" action="/kjw0612/awesome-deep-vision/search" class="js-site-search-form" data-global-search-url="/search" data-repo-search-url="/kjw0612/awesome-deep-vision/search" method="get"><div style="margin:0;padding:0;display:inline"><input name="utf8" type="hidden" value="&#x2713;" /></div>
  <label class="js-chromeless-input-container form-control">
    <div class="scope-badge">This repository</div>
    <input type="text"
      class="js-site-search-focus js-site-search-field is-clearable chromeless-input"
      data-hotkey="s"
      name="q"
      placeholder="Search"
      aria-label="Search this repository"
      data-global-scope-placeholder="Search GitHub"
      data-repo-scope-placeholder="Search"
      tabindex="1"
      autocapitalize="off">
  </label>
</form>
      </div>

      <ul class="header-nav left" role="navigation">
        <li class="header-nav-item">
          <a href="/pulls" class="js-selected-navigation-item header-nav-link" data-ga-click="Header, click, Nav menu - item:pulls context:user" data-hotkey="g p" data-selected-links="/pulls /pulls/assigned /pulls/mentioned /pulls">
            Pull requests
</a>        </li>
        <li class="header-nav-item">
          <a href="/issues" class="js-selected-navigation-item header-nav-link" data-ga-click="Header, click, Nav menu - item:issues context:user" data-hotkey="g i" data-selected-links="/issues /issues/assigned /issues/mentioned /issues">
            Issues
</a>        </li>
          <li class="header-nav-item">
            <a class="header-nav-link" href="https://gist.github.com/" data-ga-click="Header, go to gist, text:gist">Gist</a>
          </li>
      </ul>

    
<ul class="header-nav user-nav right" id="user-links">
  <li class="header-nav-item">
      <span class="js-socket-channel js-updatable-content"
        data-channel="notification-changed:smajida"
        data-url="/notifications/header">
      <a href="/notifications" aria-label="You have no unread notifications" class="header-nav-link notification-indicator tooltipped tooltipped-s" data-ga-click="Header, go to notifications, icon:read" data-hotkey="g n">
          <span class="mail-status all-read"></span>
          <span class="octicon octicon-bell"></span>
</a>  </span>

  </li>

  <li class="header-nav-item dropdown js-menu-container">
    <a class="header-nav-link tooltipped tooltipped-s js-menu-target" href="/new"
       aria-label="Create new…"
       data-ga-click="Header, create new, icon:add">
      <span class="octicon octicon-plus left"></span>
      <span class="dropdown-caret"></span>
    </a>

    <div class="dropdown-menu-content js-menu-content">
      <ul class="dropdown-menu dropdown-menu-sw">
        
<a class="dropdown-item" href="/new" data-ga-click="Header, create new repository">
  New repository
</a>


  <a class="dropdown-item" href="/organizations/new" data-ga-click="Header, create new organization">
    New organization
  </a>



  <div class="dropdown-divider"></div>
  <div class="dropdown-header">
    <span title="kjw0612/awesome-deep-vision">This repository</span>
  </div>
    <a class="dropdown-item" href="/kjw0612/awesome-deep-vision/issues/new" data-ga-click="Header, create new issue">
      New issue
    </a>

      </ul>
    </div>
  </li>

  <li class="header-nav-item dropdown js-menu-container">
    <a class="header-nav-link name tooltipped tooltipped-s js-menu-target" href="/smajida"
       aria-label="View profile and more"
       data-ga-click="Header, show menu, icon:avatar">
      <img alt="@smajida" class="avatar" height="20" src="https://avatars1.githubusercontent.com/u/12903362?v=3&amp;s=40" width="20" />
      <span class="dropdown-caret"></span>
    </a>

    <div class="dropdown-menu-content js-menu-content">
      <div class="dropdown-menu dropdown-menu-sw">
        <div class="dropdown-header header-nav-current-user css-truncate">
          Signed in as <strong class="css-truncate-target">smajida</strong>
        </div>
        <div class="dropdown-divider"></div>

        <a class="dropdown-item" href="/smajida" data-ga-click="Header, go to profile, text:your profile">
          Your profile
        </a>
        <a class="dropdown-item" href="/stars" data-ga-click="Header, go to starred repos, text:your stars">
          Your stars
        </a>
        <a class="dropdown-item" href="/explore" data-ga-click="Header, go to explore, text:explore">
          Explore
        </a>
        <a class="dropdown-item" href="https://help.github.com" data-ga-click="Header, go to help, text:help">
          Help
        </a>
        <div class="dropdown-divider"></div>

        <a class="dropdown-item" href="/settings/profile" data-ga-click="Header, go to settings, icon:settings">
          Settings
        </a>

        <!-- </textarea> --><!-- '"` --><form accept-charset="UTF-8" action="/logout" class="logout-form" data-form-nonce="722279213b9f61f1fc9f5f6cc19a8243c427cb59" method="post"><div style="margin:0;padding:0;display:inline"><input name="utf8" type="hidden" value="&#x2713;" /><input name="authenticity_token" type="hidden" value="i7RbXuUnaMqvAUcdYoE59vbPByqMTsOLw6Me2gtAa3AtlBgQ9gNVb/eckBzophVOj9HiMObm82erSqsBjz5BKA==" /></div>
          <button class="dropdown-item dropdown-signout" data-ga-click="Header, sign out, icon:logout">
            Sign out
          </button>
</form>      </div>
    </div>
  </li>
</ul>


    
  </div>
</div>

        

        


      <div id="start-of-content" class="accessibility-aid"></div>

      <div id="js-flash-container">
</div>


          <div itemscope itemtype="http://schema.org/WebPage">
    <div class="pagehead repohead instapaper_ignore readability-menu">
      <div class="container">

        <div class="clearfix">
          
<ul class="pagehead-actions">

  <li>
      <!-- </textarea> --><!-- '"` --><form accept-charset="UTF-8" action="/notifications/subscribe" class="js-social-container" data-autosubmit="true" data-form-nonce="722279213b9f61f1fc9f5f6cc19a8243c427cb59" data-remote="true" method="post"><div style="margin:0;padding:0;display:inline"><input name="utf8" type="hidden" value="&#x2713;" /><input name="authenticity_token" type="hidden" value="QrloHk8RLReiYdDnp0N+bIPROujb2Ph7oTEmlhse4MVVVgEB9nXt3i01IUMBmpAQjEMCi1pQhQkdx0dq2SOYjQ==" /></div>    <input id="repository_id" name="repository_id" type="hidden" value="35812923" />

      <div class="select-menu js-menu-container js-select-menu">
        <a href="/kjw0612/awesome-deep-vision/subscription"
          class="btn btn-sm btn-with-count select-menu-button js-menu-target" role="button" tabindex="0" aria-haspopup="true"
          data-ga-click="Repository, click Watch settings, action:blob#show">
          <span class="js-select-button">
            <span class="octicon octicon-eye"></span>
            Watch
          </span>
        </a>
        <a class="social-count js-social-count" href="/kjw0612/awesome-deep-vision/watchers">
          57
        </a>

        <div class="select-menu-modal-holder">
          <div class="select-menu-modal subscription-menu-modal js-menu-content" aria-hidden="true">
            <div class="select-menu-header">
              <span class="select-menu-title">Notifications</span>
              <span class="octicon octicon-x js-menu-close" role="button" aria-label="Close"></span>
            </div>

            <div class="select-menu-list js-navigation-container" role="menu">

              <div class="select-menu-item js-navigation-item selected" role="menuitem" tabindex="0">
                <span class="select-menu-item-icon octicon octicon-check"></span>
                <div class="select-menu-item-text">
                  <input checked="checked" id="do_included" name="do" type="radio" value="included" />
                  <span class="select-menu-item-heading">Not watching</span>
                  <span class="description">Be notified when participating or @mentioned.</span>
                  <span class="js-select-button-text hidden-select-button-text">
                    <span class="octicon octicon-eye"></span>
                    Watch
                  </span>
                </div>
              </div>

              <div class="select-menu-item js-navigation-item " role="menuitem" tabindex="0">
                <span class="select-menu-item-icon octicon octicon octicon-check"></span>
                <div class="select-menu-item-text">
                  <input id="do_subscribed" name="do" type="radio" value="subscribed" />
                  <span class="select-menu-item-heading">Watching</span>
                  <span class="description">Be notified of all conversations.</span>
                  <span class="js-select-button-text hidden-select-button-text">
                    <span class="octicon octicon-eye"></span>
                    Unwatch
                  </span>
                </div>
              </div>

              <div class="select-menu-item js-navigation-item " role="menuitem" tabindex="0">
                <span class="select-menu-item-icon octicon octicon-check"></span>
                <div class="select-menu-item-text">
                  <input id="do_ignore" name="do" type="radio" value="ignore" />
                  <span class="select-menu-item-heading">Ignoring</span>
                  <span class="description">Never be notified.</span>
                  <span class="js-select-button-text hidden-select-button-text">
                    <span class="octicon octicon-mute"></span>
                    Stop ignoring
                  </span>
                </div>
              </div>

            </div>

          </div>
        </div>
      </div>
</form>
  </li>

  <li>
    
  <div class="js-toggler-container js-social-container starring-container ">

    <!-- </textarea> --><!-- '"` --><form accept-charset="UTF-8" action="/kjw0612/awesome-deep-vision/unstar" class="js-toggler-form starred js-unstar-button" data-form-nonce="722279213b9f61f1fc9f5f6cc19a8243c427cb59" data-remote="true" method="post"><div style="margin:0;padding:0;display:inline"><input name="utf8" type="hidden" value="&#x2713;" /><input name="authenticity_token" type="hidden" value="Z53shWZcmR6j6lbe7W4rHRlfUG484xKD6Jx9XpRVdYDB0ModiO6+54fw4D1/Njx7T7GRTWT9iELUQE6KtRMdRQ==" /></div>
      <button
        class="btn btn-sm btn-with-count js-toggler-target"
        aria-label="Unstar this repository" title="Unstar kjw0612/awesome-deep-vision"
        data-ga-click="Repository, click unstar button, action:blob#show; text:Unstar">
        <span class="octicon octicon-star"></span>
        Unstar
      </button>
        <a class="social-count js-social-count" href="/kjw0612/awesome-deep-vision/stargazers">
          188
        </a>
</form>
    <!-- </textarea> --><!-- '"` --><form accept-charset="UTF-8" action="/kjw0612/awesome-deep-vision/star" class="js-toggler-form unstarred js-star-button" data-form-nonce="722279213b9f61f1fc9f5f6cc19a8243c427cb59" data-remote="true" method="post"><div style="margin:0;padding:0;display:inline"><input name="utf8" type="hidden" value="&#x2713;" /><input name="authenticity_token" type="hidden" value="OjvdhbghxyRx1ZEQSXKvQnYzg0/rcGz0qoH5qW4Bww5Il/TuqyuO6KxEp2QDlmWd/rrohKfAbLK7ezt1DetM9w==" /></div>
      <button
        class="btn btn-sm btn-with-count js-toggler-target"
        aria-label="Star this repository" title="Star kjw0612/awesome-deep-vision"
        data-ga-click="Repository, click star button, action:blob#show; text:Star">
        <span class="octicon octicon-star"></span>
        Star
      </button>
        <a class="social-count js-social-count" href="/kjw0612/awesome-deep-vision/stargazers">
          188
        </a>
</form>  </div>

  </li>

        <li>
          <!-- </textarea> --><!-- '"` --><form accept-charset="UTF-8" action="/kjw0612/awesome-deep-vision/fork" data-form-nonce="722279213b9f61f1fc9f5f6cc19a8243c427cb59" method="post"><div style="margin:0;padding:0;display:inline"><input name="utf8" type="hidden" value="&#x2713;" /><input name="authenticity_token" type="hidden" value="XL6fTU95v5fiZ4dTFjJrQZOl4zu6kUNes3hTd5OkbFWTYugEVo8LlJ//XK4q5oNqatFsBLdR1N7epFatWxHrUA==" /></div>
            <button
                type="submit"
                class="btn btn-sm btn-with-count"
                data-ga-click="Repository, show fork modal, action:blob#show; text:Fork"
                title="Fork your own copy of kjw0612/awesome-deep-vision to your account"
                aria-label="Fork your own copy of kjw0612/awesome-deep-vision to your account">
              <span class="octicon octicon-repo-forked"></span>
              Fork
            </button>
            <a href="/kjw0612/awesome-deep-vision/network" class="social-count">72</a>
</form>        </li>

</ul>

          <h1 itemscope itemtype="http://data-vocabulary.org/Breadcrumb" class="entry-title public ">
  <span class="mega-octicon octicon-repo"></span>
  <span class="author"><a href="/kjw0612" class="url fn" itemprop="url" rel="author"><span itemprop="title">kjw0612</span></a></span><!--
--><span class="path-divider">/</span><!--
--><strong><a href="/kjw0612/awesome-deep-vision" data-pjax="#js-repo-pjax-container">awesome-deep-vision</a></strong>

  <span class="page-context-loader">
    <img alt="" height="16" src="https://assets-cdn.github.com/images/spinners/octocat-spinner-32.gif" width="16" />
  </span>

</h1>

        </div>
      </div>
    </div>

    <div class="container">
      <div class="repository-with-sidebar repo-container new-discussion-timeline ">
        <div class="repository-sidebar clearfix">
          
<nav class="sunken-menu repo-nav js-repo-nav js-sidenav-container-pjax js-octicon-loaders"
     role="navigation"
     data-pjax="#js-repo-pjax-container"
     data-issue-count-url="/kjw0612/awesome-deep-vision/issues/counts">
  <ul class="sunken-menu-group">
    <li class="tooltipped tooltipped-w" aria-label="Code">
      <a href="/kjw0612/awesome-deep-vision" aria-label="Code" aria-selected="true" class="js-selected-navigation-item selected sunken-menu-item" data-hotkey="g c" data-selected-links="repo_source repo_downloads repo_commits repo_releases repo_tags repo_branches /kjw0612/awesome-deep-vision">
        <span class="octicon octicon-code"></span> <span class="full-word">Code</span>
        <img alt="" class="mini-loader" height="16" src="https://assets-cdn.github.com/images/spinners/octocat-spinner-32.gif" width="16" />
</a>    </li>

      <li class="tooltipped tooltipped-w" aria-label="Issues">
        <a href="/kjw0612/awesome-deep-vision/issues" aria-label="Issues" class="js-selected-navigation-item sunken-menu-item" data-hotkey="g i" data-selected-links="repo_issues repo_labels repo_milestones /kjw0612/awesome-deep-vision/issues">
          <span class="octicon octicon-issue-opened"></span> <span class="full-word">Issues</span>
          <span class="js-issue-replace-counter"></span>
          <img alt="" class="mini-loader" height="16" src="https://assets-cdn.github.com/images/spinners/octocat-spinner-32.gif" width="16" />
</a>      </li>

    <li class="tooltipped tooltipped-w" aria-label="Pull requests">
      <a href="/kjw0612/awesome-deep-vision/pulls" aria-label="Pull requests" class="js-selected-navigation-item sunken-menu-item" data-hotkey="g p" data-selected-links="repo_pulls /kjw0612/awesome-deep-vision/pulls">
          <span class="octicon octicon-git-pull-request"></span> <span class="full-word">Pull requests</span>
          <span class="js-pull-replace-counter"></span>
          <img alt="" class="mini-loader" height="16" src="https://assets-cdn.github.com/images/spinners/octocat-spinner-32.gif" width="16" />
</a>    </li>

      <li class="tooltipped tooltipped-w" aria-label="Wiki">
        <a href="/kjw0612/awesome-deep-vision/wiki" aria-label="Wiki" class="js-selected-navigation-item sunken-menu-item" data-hotkey="g w" data-selected-links="repo_wiki /kjw0612/awesome-deep-vision/wiki">
          <span class="octicon octicon-book"></span> <span class="full-word">Wiki</span>
          <img alt="" class="mini-loader" height="16" src="https://assets-cdn.github.com/images/spinners/octocat-spinner-32.gif" width="16" />
</a>      </li>
  </ul>
  <div class="sunken-menu-separator"></div>
  <ul class="sunken-menu-group">

    <li class="tooltipped tooltipped-w" aria-label="Pulse">
      <a href="/kjw0612/awesome-deep-vision/pulse" aria-label="Pulse" class="js-selected-navigation-item sunken-menu-item" data-selected-links="pulse /kjw0612/awesome-deep-vision/pulse">
        <span class="octicon octicon-pulse"></span> <span class="full-word">Pulse</span>
        <img alt="" class="mini-loader" height="16" src="https://assets-cdn.github.com/images/spinners/octocat-spinner-32.gif" width="16" />
</a>    </li>

    <li class="tooltipped tooltipped-w" aria-label="Graphs">
      <a href="/kjw0612/awesome-deep-vision/graphs" aria-label="Graphs" class="js-selected-navigation-item sunken-menu-item" data-selected-links="repo_graphs repo_contributors /kjw0612/awesome-deep-vision/graphs">
        <span class="octicon octicon-graph"></span> <span class="full-word">Graphs</span>
        <img alt="" class="mini-loader" height="16" src="https://assets-cdn.github.com/images/spinners/octocat-spinner-32.gif" width="16" />
</a>    </li>
  </ul>


</nav>

            <div class="only-with-full-nav">
                
<div class="js-clone-url clone-url open"
  data-protocol-type="http">
  <h3><span class="text-emphasized">HTTPS</span> clone URL</h3>
  <div class="input-group js-zeroclipboard-container">
    <input type="text" class="input-mini input-monospace js-url-field js-zeroclipboard-target"
           value="https://github.com/kjw0612/awesome-deep-vision.git" readonly="readonly" aria-label="HTTPS clone URL">
    <span class="input-group-button">
      <button aria-label="Copy to clipboard" class="js-zeroclipboard btn btn-sm zeroclipboard-button tooltipped tooltipped-s" data-copied-hint="Copied!" type="button"><span class="octicon octicon-clippy"></span></button>
    </span>
  </div>
</div>

  
<div class="js-clone-url clone-url "
  data-protocol-type="ssh">
  <h3><span class="text-emphasized">SSH</span> clone URL</h3>
  <div class="input-group js-zeroclipboard-container">
    <input type="text" class="input-mini input-monospace js-url-field js-zeroclipboard-target"
           value="git@github.com:kjw0612/awesome-deep-vision.git" readonly="readonly" aria-label="SSH clone URL">
    <span class="input-group-button">
      <button aria-label="Copy to clipboard" class="js-zeroclipboard btn btn-sm zeroclipboard-button tooltipped tooltipped-s" data-copied-hint="Copied!" type="button"><span class="octicon octicon-clippy"></span></button>
    </span>
  </div>
</div>

  
<div class="js-clone-url clone-url "
  data-protocol-type="subversion">
  <h3><span class="text-emphasized">Subversion</span> checkout URL</h3>
  <div class="input-group js-zeroclipboard-container">
    <input type="text" class="input-mini input-monospace js-url-field js-zeroclipboard-target"
           value="https://github.com/kjw0612/awesome-deep-vision" readonly="readonly" aria-label="Subversion checkout URL">
    <span class="input-group-button">
      <button aria-label="Copy to clipboard" class="js-zeroclipboard btn btn-sm zeroclipboard-button tooltipped tooltipped-s" data-copied-hint="Copied!" type="button"><span class="octicon octicon-clippy"></span></button>
    </span>
  </div>
</div>



  <div class="clone-options">You can clone with
    <!-- </textarea> --><!-- '"` --><form accept-charset="UTF-8" action="/users/set_protocol?protocol_selector=http&amp;protocol_type=clone" class="inline-form js-clone-selector-form is-enabled" data-form-nonce="722279213b9f61f1fc9f5f6cc19a8243c427cb59" data-remote="true" method="post"><div style="margin:0;padding:0;display:inline"><input name="utf8" type="hidden" value="&#x2713;" /><input name="authenticity_token" type="hidden" value="gpvXausVRzStf5k42XetoaUA4g68DJjepUZxV3SJ2jsfzHFd/DcA8wmPzfPdHc8I8H8J2xprj4uGPI4sXirElQ==" /></div><button class="btn-link js-clone-selector" data-protocol="http" type="submit">HTTPS</button></form>, <!-- </textarea> --><!-- '"` --><form accept-charset="UTF-8" action="/users/set_protocol?protocol_selector=ssh&amp;protocol_type=clone" class="inline-form js-clone-selector-form is-enabled" data-form-nonce="722279213b9f61f1fc9f5f6cc19a8243c427cb59" data-remote="true" method="post"><div style="margin:0;padding:0;display:inline"><input name="utf8" type="hidden" value="&#x2713;" /><input name="authenticity_token" type="hidden" value="NEXbn+O3gfjbezXefGqKQZpprg0bliR3sxzbsvh5FAMdEM4X1XAydwKG5Gno/To4AJYjjDemg0gx5YAcAXmOPQ==" /></div><button class="btn-link js-clone-selector" data-protocol="ssh" type="submit">SSH</button></form>, or <!-- </textarea> --><!-- '"` --><form accept-charset="UTF-8" action="/users/set_protocol?protocol_selector=subversion&amp;protocol_type=clone" class="inline-form js-clone-selector-form is-enabled" data-form-nonce="722279213b9f61f1fc9f5f6cc19a8243c427cb59" data-remote="true" method="post"><div style="margin:0;padding:0;display:inline"><input name="utf8" type="hidden" value="&#x2713;" /><input name="authenticity_token" type="hidden" value="8IWhn3g1TcT5L4asrkRHlxwviPEYNSl0SjARuZECOXgikgD9HeBrfaZmMxeelt8QyYm+FpaNE9F/p03GV4LJqA==" /></div><button class="btn-link js-clone-selector" data-protocol="subversion" type="submit">Subversion</button></form>.
    <a href="https://help.github.com/articles/which-remote-url-should-i-use" class="help tooltipped tooltipped-n" aria-label="Get help on which URL is right for you.">
      <span class="octicon octicon-question"></span>
    </a>
  </div>

              <a href="/kjw0612/awesome-deep-vision/archive/master.zip"
                 class="btn btn-sm sidebar-button"
                 aria-label="Download the contents of kjw0612/awesome-deep-vision as a zip file"
                 title="Download the contents of kjw0612/awesome-deep-vision as a zip file"
                 rel="nofollow">
                <span class="octicon octicon-cloud-download"></span>
                Download ZIP
              </a>
            </div>
        </div>
        <div id="js-repo-pjax-container" class="repository-content context-loader-container" data-pjax-container>

          

<a href="/kjw0612/awesome-deep-vision/blob/362887aecaee40ae3f3f461970219dcce13116e7/README.md" class="hidden js-permalink-shortcut" data-hotkey="y">Permalink</a>

<!-- blob contrib key: blob_contributors:v21:06e8b4fbe36e0870d69db447926fbc19 -->

  <div class="file-navigation js-zeroclipboard-container">
    
<div class="select-menu js-menu-container js-select-menu left">
  <span class="btn btn-sm select-menu-button js-menu-target css-truncate" data-hotkey="w"
    data-ref="master"
    title="master"
    role="button" aria-label="Switch branches or tags" tabindex="0" aria-haspopup="true">
    <i>Branch:</i>
    <span class="js-select-button css-truncate-target">master</span>
  </span>

  <div class="select-menu-modal-holder js-menu-content js-navigation-container" data-pjax aria-hidden="true">

    <div class="select-menu-modal">
      <div class="select-menu-header">
        <span class="select-menu-title">Switch branches/tags</span>
        <span class="octicon octicon-x js-menu-close" role="button" aria-label="Close"></span>
      </div>

      <div class="select-menu-filters">
        <div class="select-menu-text-filter">
          <input type="text" aria-label="Filter branches/tags" id="context-commitish-filter-field" class="js-filterable-field js-navigation-enable" placeholder="Filter branches/tags">
        </div>
        <div class="select-menu-tabs">
          <ul>
            <li class="select-menu-tab">
              <a href="#" data-tab-filter="branches" data-filter-placeholder="Filter branches/tags" class="js-select-menu-tab" role="tab">Branches</a>
            </li>
            <li class="select-menu-tab">
              <a href="#" data-tab-filter="tags" data-filter-placeholder="Find a tag…" class="js-select-menu-tab" role="tab">Tags</a>
            </li>
          </ul>
        </div>
      </div>

      <div class="select-menu-list select-menu-tab-bucket js-select-menu-tab-bucket" data-tab-filter="branches" role="menu">

        <div data-filterable-for="context-commitish-filter-field" data-filterable-type="substring">


            <a class="select-menu-item js-navigation-item js-navigation-open "
               href="/kjw0612/awesome-deep-vision/blob/gh-pages/README.md"
               data-name="gh-pages"
               data-skip-pjax="true"
               rel="nofollow">
              <span class="select-menu-item-icon octicon octicon-check"></span>
              <span class="select-menu-item-text css-truncate-target" title="gh-pages">
                gh-pages
              </span>
            </a>
            <a class="select-menu-item js-navigation-item js-navigation-open selected"
               href="/kjw0612/awesome-deep-vision/blob/master/README.md"
               data-name="master"
               data-skip-pjax="true"
               rel="nofollow">
              <span class="select-menu-item-icon octicon octicon-check"></span>
              <span class="select-menu-item-text css-truncate-target" title="master">
                master
              </span>
            </a>
        </div>

          <div class="select-menu-no-results">Nothing to show</div>
      </div>

      <div class="select-menu-list select-menu-tab-bucket js-select-menu-tab-bucket" data-tab-filter="tags">
        <div data-filterable-for="context-commitish-filter-field" data-filterable-type="substring">


        </div>

        <div class="select-menu-no-results">Nothing to show</div>
      </div>

    </div>
  </div>
</div>

    <div class="btn-group right">
      <a href="/kjw0612/awesome-deep-vision/find/master"
            class="js-show-file-finder btn btn-sm empty-icon tooltipped tooltipped-nw"
            data-pjax
            data-hotkey="t"
            aria-label="Quickly jump between files">
        <span class="octicon octicon-list-unordered"></span>
      </a>
      <button aria-label="Copy file path to clipboard" class="js-zeroclipboard btn btn-sm zeroclipboard-button tooltipped tooltipped-s" data-copied-hint="Copied!" type="button"><span class="octicon octicon-clippy"></span></button>
    </div>

    <div class="breadcrumb js-zeroclipboard-target">
      <span class="repo-root js-repo-root"><span itemscope="" itemtype="http://data-vocabulary.org/Breadcrumb"><a href="/kjw0612/awesome-deep-vision" class="" data-branch="master" data-pjax="true" itemscope="url"><span itemprop="title">awesome-deep-vision</span></a></span></span><span class="separator">/</span><strong class="final-path">README.md</strong>
    </div>
  </div>


  <div class="commit file-history-tease">
    <div class="file-history-tease-header">
        <img alt="@myungsub" class="avatar" height="24" src="https://avatars1.githubusercontent.com/u/7778428?v=3&amp;s=48" width="24" />
        <span class="author"><a href="/myungsub" rel="contributor">myungsub</a></span>
        <time datetime="2015-08-21T07:48:01Z" is="relative-time">Aug 21, 2015</time>
        <div class="commit-title">
            <a href="/kjw0612/awesome-deep-vision/commit/362887aecaee40ae3f3f461970219dcce13116e7" class="message" data-pjax="true" title="Update captioning papers">Update captioning papers</a>
        </div>
    </div>

    <div class="participation">
      <p class="quickstat">
        <a href="#blob_contributors_box" rel="facebox">
          <strong>8</strong>
           contributors
        </a>
      </p>
          <a class="avatar-link tooltipped tooltipped-s" aria-label="kjw0612" href="/kjw0612/awesome-deep-vision/commits/master/README.md?author=kjw0612"><img alt="@kjw0612" class="avatar" height="20" src="https://avatars3.githubusercontent.com/u/2831504?v=3&amp;s=40" width="20" /> </a>
    <a class="avatar-link tooltipped tooltipped-s" aria-label="hmyeong" href="/kjw0612/awesome-deep-vision/commits/master/README.md?author=hmyeong"><img alt="@hmyeong" class="avatar" height="20" src="https://avatars2.githubusercontent.com/u/4350435?v=3&amp;s=40" width="20" /> </a>
    <a class="avatar-link tooltipped tooltipped-s" aria-label="myungsub" href="/kjw0612/awesome-deep-vision/commits/master/README.md?author=myungsub"><img alt="@myungsub" class="avatar" height="20" src="https://avatars3.githubusercontent.com/u/7778428?v=3&amp;s=40" width="20" /> </a>
    <a class="avatar-link tooltipped tooltipped-s" aria-label="deruci" href="/kjw0612/awesome-deep-vision/commits/master/README.md?author=deruci"><img alt="@deruci" class="avatar" height="20" src="https://avatars0.githubusercontent.com/u/5226447?v=3&amp;s=40" width="20" /> </a>
    <a class="avatar-link tooltipped tooltipped-s" aria-label="shicai" href="/kjw0612/awesome-deep-vision/commits/master/README.md?author=shicai"><img alt="@shicai" class="avatar" height="20" src="https://avatars2.githubusercontent.com/u/3377970?v=3&amp;s=40" width="20" /> </a>
    <a class="avatar-link tooltipped tooltipped-s" aria-label="bayerj" href="/kjw0612/awesome-deep-vision/commits/master/README.md?author=bayerj"><img alt="@bayerj" class="avatar" height="20" src="https://avatars0.githubusercontent.com/u/50352?v=3&amp;s=40" width="20" /> </a>
    <a class="avatar-link tooltipped tooltipped-s" aria-label="gitter-badger" href="/kjw0612/awesome-deep-vision/commits/master/README.md?author=gitter-badger"><img alt="@gitter-badger" class="avatar" height="20" src="https://avatars0.githubusercontent.com/u/8518239?v=3&amp;s=40" width="20" /> </a>
    <a class="avatar-link tooltipped tooltipped-s" aria-label="CraigyDavi" href="/kjw0612/awesome-deep-vision/commits/master/README.md?author=CraigyDavi"><img alt="@CraigyDavi" class="avatar" height="20" src="https://avatars0.githubusercontent.com/u/5341072?v=3&amp;s=40" width="20" /> </a>


    </div>
    <div id="blob_contributors_box" style="display:none">
      <h2 class="facebox-header" id="facebox-header">Users who have contributed to this file</h2>
      <ul class="facebox-user-list" id="facebox-description">
          <li class="facebox-user-list-item">
            <img alt="@kjw0612" height="24" src="https://avatars1.githubusercontent.com/u/2831504?v=3&amp;s=48" width="24" />
            <a href="/kjw0612">kjw0612</a>
          </li>
          <li class="facebox-user-list-item">
            <img alt="@hmyeong" height="24" src="https://avatars0.githubusercontent.com/u/4350435?v=3&amp;s=48" width="24" />
            <a href="/hmyeong">hmyeong</a>
          </li>
          <li class="facebox-user-list-item">
            <img alt="@myungsub" height="24" src="https://avatars1.githubusercontent.com/u/7778428?v=3&amp;s=48" width="24" />
            <a href="/myungsub">myungsub</a>
          </li>
          <li class="facebox-user-list-item">
            <img alt="@deruci" height="24" src="https://avatars2.githubusercontent.com/u/5226447?v=3&amp;s=48" width="24" />
            <a href="/deruci">deruci</a>
          </li>
          <li class="facebox-user-list-item">
            <img alt="@shicai" height="24" src="https://avatars0.githubusercontent.com/u/3377970?v=3&amp;s=48" width="24" />
            <a href="/shicai">shicai</a>
          </li>
          <li class="facebox-user-list-item">
            <img alt="@bayerj" height="24" src="https://avatars2.githubusercontent.com/u/50352?v=3&amp;s=48" width="24" />
            <a href="/bayerj">bayerj</a>
          </li>
          <li class="facebox-user-list-item">
            <img alt="@gitter-badger" height="24" src="https://avatars2.githubusercontent.com/u/8518239?v=3&amp;s=48" width="24" />
            <a href="/gitter-badger">gitter-badger</a>
          </li>
          <li class="facebox-user-list-item">
            <img alt="@CraigyDavi" height="24" src="https://avatars2.githubusercontent.com/u/5341072?v=3&amp;s=48" width="24" />
            <a href="/CraigyDavi">CraigyDavi</a>
          </li>
      </ul>
    </div>
  </div>

<div class="file">
  <div class="file-header">
    <div class="file-actions">

      <div class="btn-group">
        <a href="/kjw0612/awesome-deep-vision/raw/master/README.md" class="btn btn-sm " id="raw-url">Raw</a>
          <a href="/kjw0612/awesome-deep-vision/blame/master/README.md" class="btn btn-sm js-update-url-with-hash">Blame</a>
        <a href="/kjw0612/awesome-deep-vision/commits/master/README.md" class="btn btn-sm " rel="nofollow">History</a>
      </div>


            <!-- </textarea> --><!-- '"` --><form accept-charset="UTF-8" action="/kjw0612/awesome-deep-vision/edit/master/README.md" class="inline-form" data-form-nonce="722279213b9f61f1fc9f5f6cc19a8243c427cb59" method="post"><div style="margin:0;padding:0;display:inline"><input name="utf8" type="hidden" value="&#x2713;" /><input name="authenticity_token" type="hidden" value="m9nEMKJJ3z53yAzZK0QxL1V2yC5wcNI1IV07viPMBkjyi4WHmNmNG1eDHxYi6WnjiFBZdPrmUbXhAg4OaEpG8w==" /></div>
              <button class="octicon-btn tooltipped tooltipped-n" type="submit" aria-label="Fork this project and edit the file" data-hotkey="e" data-disable-with>
                <span class="octicon octicon-pencil"></span>
              </button>
</form>
          <!-- </textarea> --><!-- '"` --><form accept-charset="UTF-8" action="/kjw0612/awesome-deep-vision/delete/master/README.md" class="inline-form" data-form-nonce="722279213b9f61f1fc9f5f6cc19a8243c427cb59" method="post"><div style="margin:0;padding:0;display:inline"><input name="utf8" type="hidden" value="&#x2713;" /><input name="authenticity_token" type="hidden" value="pB622j/R7OnyCp1COZJaZLL96RUjULtupbhk3M+oJiA6gYOLP8qREqHpgl/UGw51xLGGE0PaWkQplXM1QsG41w==" /></div>
            <button class="octicon-btn octicon-btn-danger tooltipped tooltipped-n" type="submit" aria-label="Fork this project and delete this file" data-disable-with>
              <span class="octicon octicon-trashcan"></span>
            </button>
</form>    </div>

    <div class="file-info">
        310 lines (273 sloc)
        <span class="file-info-divider"></span>
      29.837 kB
    </div>
  </div>
  
  <div id="readme" class="blob instapaper_body">
    <article class="markdown-body entry-content" itemprop="mainContentOfPage"><h1><a id="user-content-awesome-deep-vision-" class="anchor" href="#awesome-deep-vision-" aria-hidden="true"><span class="octicon octicon-link"></span></a>Awesome Deep Vision <a href="https://github.com/sindresorhus/awesome"><img src="https://camo.githubusercontent.com/13c4e50d88df7178ae1882a203ed57b641674f94/68747470733a2f2f63646e2e7261776769742e636f6d2f73696e647265736f726875732f617765736f6d652f643733303566333864323966656437386661383536353265336136336531353464643865383832392f6d656469612f62616467652e737667" alt="Awesome" data-canonical-src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg" style="max-width:100%;"></a></h1>

<p>A curated list of deep learning resources for computer vision, inspired by <a href="https://github.com/ziadoz/awesome-php">awesome-php</a> and <a href="https://github.com/jbhuang0604/awesome-computer-vision">awesome-computer-vision</a>.</p>

<p>Maintainers - <a href="http://github.com/kjw0612">Jiwon Kim</a>, <a href="https://github.com/hmyeong">Heesoo Myeong</a>, <a href="http://github.com/myungsub">Myungsub Choi</a>, <a href="https://github.com/JanghoonChoi">JanghoonChoi</a>, <a href="http://github.com/deruci">Jung Kwon Lee</a></p>

<h2><a id="user-content-contributing" class="anchor" href="#contributing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Contributing</h2>

<p>Please feel free to <a href="https://github.com/kjw0612/awesome-deep-vision/pulls">pull requests</a>, email <a href="mailto:jiwon@alum.mit.edu">jiwon@alum.mit.edu</a> or join our chats to add links. </p>

<p><a href="https://gitter.im/kjw0612/awesome-deep-vision?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge"><img src="https://camo.githubusercontent.com/da2edb525cde1455a622c58c0effc3a90b9a181c/68747470733a2f2f6261646765732e6769747465722e696d2f4a6f696e253230436861742e737667" alt="Join the chat at https://gitter.im/kjw0612/awesome-deep-vision" data-canonical-src="https://badges.gitter.im/Join%20Chat.svg" style="max-width:100%;"></a></p>

<h2><a id="user-content-sharing" class="anchor" href="#sharing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Sharing</h2>

<ul>
<li><a href="http://twitter.com/home?status=http://jiwonkim.org/awesome-deep-vision%0ADeep%20Learning%20Resources%20for%20Computer%20Vision">Share on Twitter</a></li>
<li><a href="http://www.facebook.com/sharer/sharer.php?u=https://jiwonkim.org/awesome-deep-vision">Share on Facebook</a></li>
<li><a href="http://plus.google.com/share?url=https://jiwonkim.org/awesome-deep-vision">Share on Google Plus</a></li>
<li><a href="http://www.linkedin.com/shareArticle?mini=true&amp;url=https://jiwonkim.org/awesome-deep-vision&amp;title=Awesome%20Deep%20Vision&amp;summary=&amp;source=">Share on LinkedIn</a></li>
</ul>

<h2><a id="user-content-table-of-contents" class="anchor" href="#table-of-contents" aria-hidden="true"><span class="octicon octicon-link"></span></a>Table of Contents</h2>

<ul>
<li><a href="#papers">Papers</a>

<ul>
<li><a href="#imagenet-classification">ImageNet Classification</a></li>
<li><a href="#object-detection">Object Detection</a></li>
<li><a href="#object-tracking">Object Tracking</a></li>
<li><a href="#low-level-vision">Low-Level Vision</a></li>
<li><a href="#edge-detection">Edge Detection</a></li>
<li><a href="#semantic-segmentation">Semantic Segmentation</a></li>
<li><a href="#visual-attention-and-saliency">Visual Attention and Saliency</a></li>
<li><a href="#object-recognition">Object Recognition</a></li>
<li><a href="#understanding-cnn">Understanding CNN</a></li>
<li><a href="#image-captioning">Image Captioning</a></li>
<li><a href="#video-captioning">Video Captioning</a></li>
<li><a href="#question-answering">Question Answering</a></li>
<li><a href="#other-topics">Other Topics</a></li>
</ul></li>
<li><a href="#courses">Courses</a></li>
<li><a href="#books">Books</a></li>
<li><a href="#videos">Videos</a></li>
<li><a href="#software">Software</a>

<ul>
<li><a href="#framework">Framework</a></li>
<li><a href="#applications">Applications</a></li>
</ul></li>
<li><a href="#tutorials">Tutorials</a></li>
<li><a href="#blogs">Blogs</a></li>
</ul>

<h2><a id="user-content-papers" class="anchor" href="#papers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Papers</h2>

<h3><a id="user-content-imagenet-classification" class="anchor" href="#imagenet-classification" aria-hidden="true"><span class="octicon octicon-link"></span></a>ImageNet Classification</h3>

<p><a href="https://cloud.githubusercontent.com/assets/5226447/8451949/327b9566-2022-11e5-8b34-53b4a64c13ad.PNG" target="_blank"><img src="https://cloud.githubusercontent.com/assets/5226447/8451949/327b9566-2022-11e5-8b34-53b4a64c13ad.PNG" alt="classification" style="max-width:100%;"></a>
(from Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton, ImageNet Classification with Deep Convolutional Neural Networks, NIPS, 2012.)</p>

<ul>
<li>Microsoft (PReLu/Weight Initialization) <a href="http://arxiv.org/pdf/1502.01852">[Paper]</a>

<ul>
<li>Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification, arXiv:1502.01852.</li>
</ul></li>
<li>Batch Normalization <a href="http://arxiv.org/pdf/1502.03167">[Paper]</a>

<ul>
<li>Sergey Ioffe, Christian Szegedy, Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift, arXiv:1502.03167.</li>
</ul></li>
<li>GoogLeNet <a href="http://arxiv.org/pdf/1409.4842">[Paper]</a>

<ul>
<li>Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich, CVPR, 2015. </li>
</ul></li>
<li>VGG-Net <a href="http://www.robots.ox.ac.uk/%7Evgg/research/very_deep/">[Web]</a> <a href="http://arxiv.org/pdf/1409.1556">[Paper]</a>

<ul>
<li>Karen Simonyan and Andrew Zisserman, Very Deep Convolutional Networks for Large-Scale Visual Recognition, ICLR, 2015.</li>
</ul></li>
<li>AlexNet <a href="http://books.nips.cc/papers/files/nips25/NIPS2012_0534.pdf">[Paper]</a>

<ul>
<li>Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton, ImageNet Classification with Deep Convolutional Neural Networks, NIPS, 2012.</li>
</ul></li>
</ul>

<h3><a id="user-content-object-detection" class="anchor" href="#object-detection" aria-hidden="true"><span class="octicon octicon-link"></span></a>Object Detection</h3>

<p><a href="https://cloud.githubusercontent.com/assets/5226447/8452063/f76ba500-2022-11e5-8db1-2cd5d490e3b3.PNG" target="_blank"><img src="https://cloud.githubusercontent.com/assets/5226447/8452063/f76ba500-2022-11e5-8db1-2cd5d490e3b3.PNG" alt="object_detection" style="max-width:100%;"></a>
(from Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun, Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks, arXiv:1506.01497.)</p>

<ul>
<li>OverFeat, NYU <a href="http://arxiv.org/pdf/1311.2901">[Paper]</a>

<ul>
<li>Matthrew Zeiler, Rob Fergus, Visualizing and Understanding Convolutional Networks, ECCV, 2014.</li>
</ul></li>
<li>R-CNN, UC Berkeley <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf">[Paper-CVPR14]</a> <a href="http://arxiv.org/pdf/1311.2524">[Paper-arXiv14]</a>

<ul>
<li>Ross Girshick, Jeff Donahue, Trevor Darrell, Jitendra Malik, Rich feature hierarchies for accurate object detection and semantic segmentation, CVPR, 2014.</li>
</ul></li>
<li>SPP, Microsoft Research <a href="http://arxiv.org/pdf/1406.4729">[Paper]</a>

<ul>
<li>Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition, ECCV, 2014.</li>
</ul></li>
<li>Fast R-CNN, Microsoft Research <a href="http://arxiv.org/pdf/1504.08083">[Paper]</a>

<ul>
<li>Ross Girshick, Fast R-CNN, arXiv:1504.08083.</li>
</ul></li>
<li>Faster R-CNN, Microsoft Research <a href="http://arxiv.org/pdf/1506.01497">[Paper]</a>

<ul>
<li>Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun, Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks, arXiv:1506.01497.</li>
</ul></li>
<li>R-CNN minus R, Oxford <a href="http://arxiv.org/pdf/1506.06981">[Paper]</a>

<ul>
<li>Karel Lenc, Andrea Vedaldi, R-CNN minus R, arXiv:1506.06981.</li>
</ul></li>
</ul>

<h3><a id="user-content-object-tracking" class="anchor" href="#object-tracking" aria-hidden="true"><span class="octicon octicon-link"></span></a>Object Tracking</h3>

<ul>
<li>Seunghoon Hong, Tackgeun You, Suha Kwak, Bohyung Han, Online Tracking by Learning Discriminative Saliency Map with Convolutional Neural Network, arXiv:1502.06796. <a href="http://arxiv.org/pdf/1502.06796">[Paper]</a></li>
<li>Hanxi Li, Yi Li and Fatih Porikli, DeepTrack: Learning Discriminative Feature Representations by Convolutional Neural Networks for Visual Tracking, BMVC, 2014. <a href="http://www.bmva.org/bmvc/2014/files/paper028.pdf">[Paper]</a></li>
<li>N Wang, DY Yeung, Learning a Deep Compact Image Representation for Visual Tracking, NIPS, 2013. <a href="http://winsty.net/papers/dlt.pdf">[Paper]</a></li>
</ul>

<h3><a id="user-content-low-level-vision" class="anchor" href="#low-level-vision" aria-hidden="true"><span class="octicon octicon-link"></span></a>Low-Level Vision</h3>

<ul>
<li>Optical Flow (FlowNet) <a href="http://arxiv.org/pdf/1504.06852">[Paper]</a>

<ul>
<li>Philipp Fischer, Alexey Dosovitskiy, Eddy Ilg, Philip Häusser, Caner Hazırbaş, Vladimir Golkov, Patrick van der Smagt, Daniel Cremers, Thomas Brox, FlowNet: Learning Optical Flow with Convolutional Networks, arXiv:1504.06852.</li>
</ul></li>
<li>Super-Resolution (SRCNN) <a href="http://mmlab.ie.cuhk.edu.hk/projects/SRCNN.html">[Web]</a> <a href="http://personal.ie.cuhk.edu.hk/%7Eccloy/files/eccv_2014_deepresolution.pdf">[Paper-ECCV14]</a> <a href="http://arxiv.org/pdf/1501.00092.pdf">[Paper-arXiv15]</a><a href="http://www.brml.org/uploads/tx_sibibtex/281.pdf">[Paper ICONIP-2014]</a>

<ul>
<li>Chao Dong, Chen Change Loy, Kaiming He, Xiaoou Tang, Learning a Deep Convolutional Network for Image Super-Resolution, ECCV, 2014.</li>
<li>Chao Dong, Chen Change Loy, Kaiming He, Xiaoou Tang, Image Super-Resolution Using Deep Convolutional Networks, arXiv:1501.00092.</li>
<li>Osendorfer, Christian, Hubert Soyer, and Patrick van der Smagt, Image Super-Resolution with Fast Approximate Convolutional Sparse Coding, ICONIP, 2014. </li>
</ul></li>
<li>Compression Artifacts Reduction <a href="http://arxiv.org/pdf/1504.06993">[Paper-arXiv15]</a>

<ul>
<li>Chao Dong, Yubin Deng, Chen Change Loy, Xiaoou Tang, Compression Artifacts Reduction by a Deep Convolutional Network, arXiv:1504.06993.</li>
</ul></li>
<li>Non-Uniform Motion Blur Removal <a href="http://arxiv.org/pdf/1503.00593">[Paper]</a>

<ul>
<li>Jian Sun, Wenfei Cao, Zongben Xu, Jean Ponce, Learning a Convolutional Neural Network for Non-uniform Motion Blur Removal, CVPR, 2015. </li>
</ul></li>
<li>Image Deconvolution <a href="http://lxu.me/projects/dcnn/">[Web]</a> <a href="http://lxu.me/mypapers/dcnn_nips14.pdf">[Paper]</a>

<ul>
<li> Li Xu, Jimmy SJ. Ren, Ce Liu, Jiaya Jia, Deep Convolutional Neural Network for Image Deconvolution, NIPS, 2014.</li>
</ul></li>
<li> Deep Edge-Aware Filter <a href="http://jmlr.org/proceedings/papers/v37/xub15.pdf">[Paper]</a>

<ul>
<li> Li Xu, Jimmy SJ. Ren, Qiong Yan, Renjie Liao, Jiaya Jia, Deep Edge-Aware Filters, ICML, 2015.</li>
</ul></li>
<li>Computing the Stereo Matching Cost with a Convolutional Neural Network <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Zbontar_Computing_the_Stereo_2015_CVPR_paper.pdf">[Paper]</a>

<ul>
<li> Jure Žbontar, Yann LeCun, Computing the Stereo Matching Cost with a Convolutional Neural Network, CVPR, 2015.</li>
</ul></li>
</ul>

<h3><a id="user-content-edge-detection" class="anchor" href="#edge-detection" aria-hidden="true"><span class="octicon octicon-link"></span></a>Edge Detection</h3>

<p><a href="https://cloud.githubusercontent.com/assets/5226447/8452371/93ca6f7e-2025-11e5-90f2-d428fd5ff7ac.PNG" target="_blank"><img src="https://cloud.githubusercontent.com/assets/5226447/8452371/93ca6f7e-2025-11e5-90f2-d428fd5ff7ac.PNG" alt="edge_detection" style="max-width:100%;"></a>
(from Gedas Bertasius, Jianbo Shi, Lorenzo Torresani, DeepEdge: A Multi-Scale Bifurcated Deep Network for Top-Down Contour Detection, CVPR, 2015.)</p>

<ul>
<li>Holistically-Nested Edge Detection <a href="http://arxiv.org/pdf/1504.06375">[Paper]</a>

<ul>
<li>Saining Xie, Zhuowen Tu, Holistically-Nested Edge Detection, arXiv:1504.06375. </li>
</ul></li>
<li>DeepEdge <a href="http://arxiv.org/pdf/1412.1123">[Paper]</a>

<ul>
<li>Gedas Bertasius, Jianbo Shi, Lorenzo Torresani, DeepEdge: A Multi-Scale Bifurcated Deep Network for Top-Down Contour Detection, CVPR, 2015.</li>
</ul></li>
<li>DeepContour <a href="http://mc.eistar.net/UpLoadFiles/Papers/DeepContour_cvpr15.pdf">[Paper]</a>

<ul>
<li>Wei Shen, Xinggang Wang, Yan Wang, Xiang Bai, Zhijiang Zhang, DeepContour: A Deep Convolutional Feature Learned by Positive-Sharing Loss for Contour Detection, CVPR, 2015.</li>
</ul></li>
</ul>

<h3><a id="user-content-semantic-segmentation" class="anchor" href="#semantic-segmentation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Semantic Segmentation</h3>

<p><a href="https://cloud.githubusercontent.com/assets/5226447/8452076/0ba8340c-2023-11e5-88bc-bebf4509b6bb.PNG" target="_blank"><img src="https://cloud.githubusercontent.com/assets/5226447/8452076/0ba8340c-2023-11e5-88bc-bebf4509b6bb.PNG" alt="semantic_segmantation" style="max-width:100%;"></a>
(from Jifeng Dai, Kaiming He, Jian Sun, BoxSup: Exploiting Bounding Boxes to Supervise Convolutional Networks for Semantic Segmentation, arXiv:1503.01640.)</p>

<ul>
<li>PASCAL VOC2012 Challenge Top 10 (14 Aug. 2015)
<a href="https://camo.githubusercontent.com/af758635177ab3d9b067199bab337581d5504876/687474703a2f2f63762e736e752e61632e6b722f686d79656f6e672f66696c65732f3135303831345f70617363616c5f766f632e706e67" target="_blank"><img src="https://camo.githubusercontent.com/af758635177ab3d9b067199bab337581d5504876/687474703a2f2f63762e736e752e61632e6b722f686d79656f6e672f66696c65732f3135303831345f70617363616c5f766f632e706e67" alt="VOC2012_top_10" data-canonical-src="http://cv.snu.ac.kr/hmyeong/files/150814_pascal_voc.png" style="max-width:100%;"></a>
(from PASCAL VOC2012 <a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&amp;compid=6">leaderboards</a>)</li>
<li>Adelaide

<ul>
<li>Guosheng Lin, Chunhua Shen, Ian Reid, Anton van dan Hengel, Efficient piecewise training of deep structured models for semantic segmentation, arXiv:1504.01013. <a href="http://arxiv.org/pdf/1504.01013">[Paper]</a> (1st ranked in VOC2012)</li>
<li>Guosheng Lin, Chunhua Shen, Ian Reid, Anton van den Hengel, Deeply Learning the Messages in Message Passing Inference, arXiv:1508.02108. <a href="http://arxiv.org/pdf/1506.02108">[Paper]</a> (4th ranked in VOC2012)</li>
</ul></li>
<li>BoxSup <a href="http://arxiv.org/pdf/1503.01640">[Paper]</a>

<ul>
<li>Jifeng Dai, Kaiming He, Jian Sun, BoxSup: Exploiting Bounding Boxes to Supervise Convolutional Networks for Semantic Segmentation, arXiv:1503.01640. (2nd ranked in VOC2012)</li>
</ul></li>
<li>Conditional Random Fields as Recurrent Neural Networks <a href="http://arxiv.org/pdf/1502.03240">[Paper]</a>

<ul>
<li>Shuai Zheng, Sadeep Jayasumana, Bernardino Romera-Paredes, Vibhav Vineet, Zhizhong Su, Dalong Du, Chang Huang, Philip H. S. Torr, Conditional Random Fields as Recurrent Neural Networks, arXiv:1502.03240. (3rd ranked in VOC2012)</li>
</ul></li>
<li>DeepLab

<ul>
<li> Liang-Chieh Chen, George Papandreou, Kevin Murphy, Alan L. Yuille, Weakly-and semi-supervised learning of a DCNN for semantic image segmentation, arXiv:1502.02734. <a href="http://arxiv.org/pdf/1502.02734">[Paper]</a> (5th ranked in VOC2012)</li>
</ul></li>
<li>POSTECH

<ul>
<li>Hyeonwoo Noh, Seunghoon Hong, Bohyung Han, Learning Deconvolution Network for Semantic Segmentation, arXiv:1505.04366. <a href="http://arxiv.org/pdf/1505.04366">[Paper]</a> (6th ranked in VOC2012)</li>
<li>Seunghoon Hong, Hyeonwoo Noh, Bohyung Han, Decoupled Deep Neural Network for Semi-supervised Semantic Segmentation, arXiv:1506.04924. <a href="http://arxiv.org/pdf/1506.04924">[Paper]</a></li>
</ul></li>
<li>Joint Calibration <a href="http://arxiv.org/pdf/1507.01581">[Paper]</a>

<ul>
<li>Holger Caesar, Jasper Uijlings, Vittorio Ferrari, Joint Calibration for Semantic Segmentation, arXiv:1507.01581.</li>
</ul></li>
<li>Fully Convolutional Networks for Semantic Segmentation <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf">[Paper-CVPR15]</a> <a href="http://arxiv.org/pdf/1411.4038">[Paper-arXiv15]</a>

<ul>
<li>Jonathan Long, Evan Shelhamer, Trevor Darrell, Fully Convolutional Networks for Semantic Segmentation, CVPR, 2015.</li>
</ul></li>
<li>Hypercolumn <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Hariharan_Hypercolumns_for_Object_2015_CVPR_paper.pdf">[Paper]</a>

<ul>
<li>Bharath Hariharan, Pablo Arbelaez, Ross Girshick, Jitendra Malik, Hypercolumns for Object Segmentation and Fine-Grained Localization, CVPR, 2015. </li>
</ul></li>
<li>Zoom-out <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Mostajabi_Feedforward_Semantic_Segmentation_2015_CVPR_paper.pdf">[Paper]</a>

<ul>
<li>Mohammadreza Mostajabi, Payman Yadollahpour, Gregory Shakhnarovich, Feedforward Semantic Segmentation With Zoom-Out Features, CVPR, 2015.</li>
</ul></li>
<li>Deep Hierarchical Parsing

<ul>
<li>Abhishek Sharma, Oncel Tuzel, David W. Jacobs, Deep Hierarchical Parsing for Semantic Segmentation, CVPR, 2015. <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Sharma_Deep_Hierarchical_Parsing_2015_CVPR_paper.pdf">[Paper]</a></li>
</ul></li>
<li>Learning Hierarchical Features for Scene Labeling <a href="http://yann.lecun.com/exdb/publis/pdf/farabet-icml-12.pdf">[Paper-ICML12]</a> <a href="http://yann.lecun.com/exdb/publis/pdf/farabet-pami-13.pdf">[Paper-PAMI13]</a>

<ul>
<li>Clement Farabet, Camille Couprie, Laurent Najman, Yann LeCun, Scene Parsing with Multiscale Feature Learning, Purity Trees, and Optimal Covers, ICML, 2012.</li>
<li>Clement Farabet, Camille Couprie, Laurent Najman, Yann LeCun, Learning Hierarchical Features for Scene Labeling, PAMI, 2013.</li>
</ul></li>
</ul>

<h3><a id="user-content-visual-attention-and-saliency" class="anchor" href="#visual-attention-and-saliency" aria-hidden="true"><span class="octicon octicon-link"></span></a>Visual Attention and Saliency</h3>

<p><a href="https://cloud.githubusercontent.com/assets/5226447/8492362/7ec65b88-2183-11e5-978f-017e45ddba32.png" target="_blank"><img src="https://cloud.githubusercontent.com/assets/5226447/8492362/7ec65b88-2183-11e5-978f-017e45ddba32.png" alt="saliency" style="max-width:100%;"></a>
(from Nian Liu, Junwei Han, Dingwen Zhang, Shifeng Wen, Tianming Liu, Predicting Eye Fixations using Convolutional Neural Networks, CVPR, 2015.)</p>

<ul>
<li>Mr-CNN <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Liu_Predicting_Eye_Fixations_2015_CVPR_paper.pdf">[Paper]</a>

<ul>
<li>Nian Liu, Junwei Han, Dingwen Zhang, Shifeng Wen, Tianming Liu, Predicting Eye Fixations using Convolutional Neural Networks, CVPR, 2015.</li>
</ul></li>
<li>Learning a Sequential Search for Landmarks <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Singh_Learning_a_Sequential_2015_CVPR_paper.pdf">[Paper]</a>

<ul>
<li>Saurabh Singh, Derek Hoiem, David Forsyth, Learning a Sequential Search for Landmarks, CVPR, 2015.</li>
</ul></li>
<li>Multiple Object Recognition with Visual Attention <a href="http://arxiv.org/pdf/1412.7755.pdf">[Paper]</a>

<ul>
<li>Jimmy Lei Ba, Volodymyr Mnih, Koray Kavukcuoglu, Multiple Object Recognition with Visual Attention, ICLR, 2015.</li>
</ul></li>
<li>Recurrent Models of Visual Attention <a href="http://papers.nips.cc/paper/5542-recurrent-models-of-visual-attention.pdf">[Paper]</a>

<ul>
<li>Volodymyr Mnih, Nicolas Heess, Alex Graves, Koray Kavukcuoglu, Recurrent Models of Visual Attention, NIPS, 2014.</li>
</ul></li>
</ul>

<h3><a id="user-content-object-recognition" class="anchor" href="#object-recognition" aria-hidden="true"><span class="octicon octicon-link"></span></a>Object Recognition</h3>

<ul>
<li>Weakly-supervised learning with convolutional neural networks <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Oquab_Is_Object_Localization_2015_CVPR_paper.pdf">[Paper]</a>

<ul>
<li>Maxime Oquab, Leon Bottou, Ivan Laptev, Josef Sivic, Is object localization for free? – Weakly-supervised learning with convolutional neural networks, CVPR, 2015.</li>
</ul></li>
<li>FV-CNN <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Cimpoi_Deep_Filter_Banks_2015_CVPR_paper.pdf">[Paper]</a>

<ul>
<li>Mircea Cimpoi, Subhransu Maji, Andrea Vedaldi, Deep Filter Banks for Texture Recognition and Segmentation, CVPR, 2015.</li>
</ul></li>
</ul>

<h3><a id="user-content-understanding-cnn" class="anchor" href="#understanding-cnn" aria-hidden="true"><span class="octicon octicon-link"></span></a>Understanding CNN</h3>

<p><a href="https://cloud.githubusercontent.com/assets/5226447/8452083/1aaa0066-2023-11e5-800b-2248ead51584.PNG" target="_blank"><img src="https://cloud.githubusercontent.com/assets/5226447/8452083/1aaa0066-2023-11e5-800b-2248ead51584.PNG" alt="understanding" style="max-width:100%;"></a>
(from Aravindh Mahendran, Andrea Vedaldi, Understanding Deep Image Representations by Inverting Them, CVPR, 2015.)</p>

<ul>
<li>Equivariance and Equivalence of Representations <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Lenc_Understanding_Image_Representations_2015_CVPR_paper.pdf">[Paper]</a>

<ul>
<li>Karel Lenc, Andrea Vedaldi, Understanding image representations by measuring their equivariance and equivalence, CVPR, 2015.</li>
</ul></li>
<li>Deep Neural Networks Are Easily Fooled <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Nguyen_Deep_Neural_Networks_2015_CVPR_paper.pdf">[Paper]</a>

<ul>
<li>Anh Nguyen, Jason Yosinski, Jeff Clune, Deep Neural Networks are Easily Fooled:High Confidence Predictions for Unrecognizable Images, CVPR, 2015.</li>
</ul></li>
<li>Understanding Deep Image Representations by Inverting Them <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Mahendran_Understanding_Deep_Image_2015_CVPR_paper.pdf">[Paper]</a>

<ul>
<li>Aravindh Mahendran, Andrea Vedaldi, Understanding Deep Image Representations by Inverting Them, CVPR, 2015.</li>
</ul></li>
</ul>

<h3><a id="user-content-image-captioning" class="anchor" href="#image-captioning" aria-hidden="true"><span class="octicon octicon-link"></span></a>Image Captioning</h3>

<p><a href="https://cloud.githubusercontent.com/assets/5226447/8452051/e8f81030-2022-11e5-85db-c68e7d8251ce.PNG" target="_blank"><img src="https://cloud.githubusercontent.com/assets/5226447/8452051/e8f81030-2022-11e5-85db-c68e7d8251ce.PNG" alt="image_captioning" style="max-width:100%;"></a>
(from Andrej Karpathy, Li Fei-Fei, Deep Visual-Semantic Alignments for Generating Image Description, CVPR, 2015.)</p>

<ul>
<li>UCLA / Baidu <a href="http://arxiv.org/pdf/1410.1090">[Paper]</a>

<ul>
<li>Junhua Mao, Wei Xu, Yi Yang, Jiang Wang, Alan L. Yuille, Explain Images with Multimodal Recurrent Neural Networks, arXiv:1410.1090.</li>
</ul></li>
<li>Toronto <a href="http://arxiv.org/pdf/1411.2539">[Paper]</a>

<ul>
<li>Ryan Kiros, Ruslan Salakhutdinov, Richard S. Zemel, Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models, arXiv:1411.2539.</li>
</ul></li>
<li>Berkeley <a href="http://arxiv.org/pdf/1411.4389">[Paper]</a>

<ul>
<li>Jeff Donahue, Lisa Anne Hendricks, Sergio Guadarrama, Marcus Rohrbach, Subhashini Venugopalan, Kate Saenko, Trevor Darrell, Long-term Recurrent Convolutional Networks for Visual Recognition and Description, arXiv:1411.4389.</li>
</ul></li>
<li>Google <a href="http://arxiv.org/pdf/1411.4555">[Paper]</a>

<ul>
<li>Oriol Vinyals, Alexander Toshev, Samy Bengio, Dumitru Erhan, Show and Tell: A Neural Image Caption Generator, arXiv:1411.4555.</li>
</ul></li>
<li>Stanford <a href="http://cs.stanford.edu/people/karpathy/deepimagesent/">[Web]</a> <a href="http://cs.stanford.edu/people/karpathy/cvpr2015.pdf">[Paper]</a>

<ul>
<li>Andrej Karpathy, Li Fei-Fei, Deep Visual-Semantic Alignments for Generating Image Description, CVPR, 2015.</li>
</ul></li>
<li>UML / UT <a href="http://arxiv.org/pdf/1412.4729">[Paper]</a>

<ul>
<li>Subhashini Venugopalan, Huijuan Xu, Jeff Donahue, Marcus Rohrbach, Raymond Mooney, Kate Saenko, Translating Videos to Natural Language Using Deep Recurrent Neural Networks, NAACL-HLT, 2015. </li>
</ul></li>
<li>CMU / Microsoft <a href="http://arxiv.org/pdf/1411.5654">[Paper-arXiv]</a> <a href="http://www.cs.cmu.edu/%7Exinleic/papers/cvpr15_rnn.pdf">[Paper-CVPR]</a>

<ul>
<li>Xinlei Chen, C. Lawrence Zitnick, Learning a Recurrent Visual Representation for Image Caption Generation, arXiv:1411.5654.</li>
<li>Xinlei Chen, C. Lawrence Zitnick, Mind’s Eye: A Recurrent Visual Representation for Image Caption Generation, CVPR 2015</li>
</ul></li>
<li>Microsoft <a href="http://arxiv.org/pdf/1411.4952">[Paper]</a>

<ul>
<li>Hao Fang, Saurabh Gupta, Forrest Iandola, Rupesh Srivastava, Li Deng, Piotr Dollár, Jianfeng Gao, Xiaodong He, Margaret Mitchell, John C. Platt, C. Lawrence Zitnick, Geoffrey Zweig, From Captions to Visual Concepts and Back, CVPR, 2015. </li>
</ul></li>
<li>Univ. Montreal / Univ. Toronto [<a href="http://kelvinxu.github.io/projects/capgen.html">Web</a>] [<a href="http://www.cs.toronto.edu/%7Ezemel/documents/captionAttn.pdf">Paper</a>]

<ul>
<li>Kelvin Xu, Jimmy Lei Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhutdinov, Richard S. Zemel, Yoshua Bengio, Show, Attend, and Tell: Neural Image Caption Generation with Visual Attention, arXiv:1502.03044 / ICML 2015</li>
</ul></li>
<li>Idiap / EPFL / Facebook [<a href="http://arxiv.org/pdf/1502.03671">Paper</a>]

<ul>
<li>Remi Lebret, Pedro O. Pinheiro, Ronan Collobert, Phrase-based Image Captioning, arXiv:1502.03671 / ICML 2015</li>
</ul></li>
<li>UCLA / Baidu [<a href="http://arxiv.org/pdf/1504.06692">Paper</a>]

<ul>
<li>Junhua Mao, Wei Xu, Yi Yang, Jiang Wang, Zhiheng Huang, Alan L. Yuille, Learning like a Child: Fast Novel Visual Concept Learning from Sentence Descriptions of Images, arXiv:1504.06692</li>
</ul></li>
<li>MS + Berkeley

<ul>
<li>Jacob Devlin, Saurabh Gupta, Ross Girshick, Margaret Mitchell, C. Lawrence Zitnick, Exploring Nearest Neighbor Approaches for Image Captioning, arXiv:1505.04467 [<a href="http://arxiv.org/pdf/1505.04467.pdf">Paper</a>]</li>
<li>Jacob Devlin, Hao Cheng, Hao Fang, Saurabh Gupta, Li Deng, Xiaodong He, Geoffrey Zweig, Margaret Mitchell, Language Models for Image Captioning: The Quirks and What Works, arXiv:1505.01809 [<a href="http://arxiv.org/pdf/1505.01809.pdf">Paper</a>]</li>
</ul></li>
<li>Adelaide [<a href="http://arxiv.org/pdf/1506.01144.pdf">Paper</a>]

<ul>
<li>Qi Wu, Chunhua Shen, Anton van den Hengel, Lingqiao Liu, Anthony Dick, Image Captioning with an Intermediate Attributes Layer, arXiv:1506.01144</li>
</ul></li>
<li>Tilburg [<a href="http://arxiv.org/pdf/1506.03694.pdf">Paper</a>]

<ul>
<li>Grzegorz Chrupala, Akos Kadar, Afra Alishahi, Learning language through pictures, arXiv:1506.03694</li>
</ul></li>
<li>Univ. Montreal [<a href="http://arxiv.org/pdf/1507.01053.pdf">Paper</a>]

<ul>
<li>Kyunghyun Cho, Aaron Courville, Yoshua Bengio, Describing Multimedia Content using Attention-based Encoder-Decoder Networks, arXiv:1507.01053</li>
</ul></li>
<li>Cornell [<a href="http://arxiv.org/pdf/1508.02091.pdf">Paper</a>]

<ul>
<li>Jack Hessel, Nicolas Savva, Michael J. Wilber, Image Representations and New Domains in Neural Image Captioning, arXiv:1508.02091 </li>
</ul></li>
</ul>

<h3><a id="user-content-video-captioning" class="anchor" href="#video-captioning" aria-hidden="true"><span class="octicon octicon-link"></span></a>Video Captioning</h3>

<ul>
<li>Berkeley <a href="http://jeffdonahue.com/lrcn/">[Web]</a> <a href="http://arxiv.org/pdf/1411.4389.pdf">[Paper]</a>

<ul>
<li>Jeff Donahue, Lisa Anne Hendricks, Sergio Guadarrama, Marcus Rohrbach, Subhashini Venugopalan, Kate Saenko, Trevor Darrell, Long-term Recurrent Convolutional Networks for Visual Recognition and Description, CVPR, 2015.</li>
</ul></li>
<li>UT / UML / Berkeley <a href="http://arxiv.org/pdf/1412.4729">[Paper]</a>

<ul>
<li>Subhashini Venugopalan, Huijuan Xu, Jeff Donahue, Marcus Rohrbach, Raymond Mooney, Kate Saenko, Translating Videos to Natural Language Using Deep Recurrent Neural Networks, arXiv:1412.4729.</li>
</ul></li>
<li>Microsoft <a href="http://arxiv.org/pdf/1505.01861">[Paper]</a>

<ul>
<li>Yingwei Pan, Tao Mei, Ting Yao, Houqiang Li, Yong Rui, Joint Modeling Embedding and Translation to Bridge Video and Language, arXiv:1505.01861.</li>
</ul></li>
<li>UT / Berkeley / UML <a href="http://arxiv.org/pdf/1505.00487">[Paper]</a>

<ul>
<li>Subhashini Venugopalan, Marcus Rohrbach, Jeff Donahue, Raymond Mooney, Trevor Darrell, Kate Saenko, Sequence to Sequence--Video to Text, arXiv:1505.00487.</li>
</ul></li>
<li>Univ. Montreal / Univ. Sherbrooke [<a href="http://arxiv.org/pdf/1502.08029.pdf">Paper</a>]

<ul>
<li>Li Yao, Atousa Torabi, Kyunghyun Cho, Nicolas Ballas, Christopher Pal, Hugo Larochelle, Aaron Courville, Describing Videos by Exploiting Temporal Structure, arXiv:1502.08029</li>
</ul></li>
<li>MPI / Berkeley [<a href="http://arxiv.org/pdf/1506.01698.pdf">Paper</a>]

<ul>
<li>Anna Rohrbach, Marcus Rohrbach, Bernt Schiele, The Long-Short Story of Movie Description, arXiv:1506.01698</li>
</ul></li>
<li>Univ. Toronto / MIT [<a href="http://arxiv.org/pdf/1506.06724.pdf">Paper</a>]

<ul>
<li>Yukun Zhu, Ryan Kiros, Richard Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba, Sanja Fidler, Aligning Books and Movies: Towards Story-like Visual Explanations by Watching Movies and Reading Books, arXiv:1506.06724</li>
</ul></li>
<li>Univ. Montreal [<a href="http://arxiv.org/pdf/1507.01053.pdf">Paper</a>]

<ul>
<li>Kyunghyun Cho, Aaron Courville, Yoshua Bengio, Describing Multimedia Content using Attention-based Encoder-Decoder Networks, arXiv:1507.01053</li>
</ul></li>
</ul>

<h3><a id="user-content-question-answering" class="anchor" href="#question-answering" aria-hidden="true"><span class="octicon octicon-link"></span></a>Question Answering</h3>

<p><a href="https://cloud.githubusercontent.com/assets/5226447/8452068/ffe7b1f6-2022-11e5-87ab-4f6d4696c220.PNG" target="_blank"><img src="https://cloud.githubusercontent.com/assets/5226447/8452068/ffe7b1f6-2022-11e5-87ab-4f6d4696c220.PNG" alt="question_answering" style="max-width:100%;"></a>
(from Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, C. Lawrence Zitnick, Devi Parikh, VQA: Visual Question Answering, CVPR, 2015 SUNw:Scene Understanding workshop)</p>

<ul>
<li>Virginia Tech / MSR <a href="http://www.visualqa.org/">[Web]</a> <a href="http://arxiv.org/pdf/1505.00468">[Paper]</a>

<ul>
<li>Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, C. Lawrence Zitnick, Devi Parikh, VQA: Visual Question Answering, CVPR, 2015 SUNw:Scene Understanding workshop.</li>
</ul></li>
<li>MPI / Berkeley <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/vision-and-language/visual-turing-challenge/">[Web]</a> <a href="http://arxiv.org/pdf/1505.01121">[Paper]</a>

<ul>
<li>Mateusz Malinowski, Marcus Rohrbach, Mario Fritz, Ask Your Neurons: A Neural-based Approach to Answering Questions about Images, arXiv:1505.01121.</li>
</ul></li>
<li>Toronto <a href="http://arxiv.org/pdf/1505.02074">[Paper]</a> <a href="http://www.cs.toronto.edu/%7Emren/imageqa/data/cocoqa/">[Dataset]</a>

<ul>
<li>Mengye Ren, Ryan Kiros, Richard Zemel, Image Question Answering: A Visual Semantic Embedding Model and a New Dataset, arXiv:1505.02074 / ICML 2015 deep learning workshop.</li>
</ul></li>
<li>Baidu / UCLA <a href="http://arxiv.org/pdf/1505.05612">[Paper]</a> <a href="/kjw0612/awesome-deep-vision/blob/master">[Dataset]</a>

<ul>
<li>Hauyuan Gao, Junhua Mao, Jie Zhou, Zhiheng Huang, Lei Wang, Wei Xu, Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question Answering, arXiv:1505.05612.</li>
</ul></li>
</ul>

<h3><a id="user-content-other-topics" class="anchor" href="#other-topics" aria-hidden="true"><span class="octicon octicon-link"></span></a>Other Topics</h3>

<ul>
<li>Surface Normal Estimation <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Wang_Designing_Deep_Networks_2015_CVPR_paper.pdf">[Paper]</a>

<ul>
<li>Xiaolong Wang, David F. Fouhey, Abhinav Gupta, Designing Deep Networks for Surface Normal Estimation, CVPR, 2015.</li>
</ul></li>
<li>Action Detection <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Gkioxari_Finding_Action_Tubes_2015_CVPR_paper.pdf">[Paper]</a>

<ul>
<li>Georgia Gkioxari, Jitendra Malik, Finding Action Tubes, CVPR, 2015.</li>
</ul></li>
<li>Crowd Counting <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Zhang_Cross-Scene_Crowd_Counting_2015_CVPR_paper.pdf">[Paper]</a>

<ul>
<li>Cong Zhang, Hongsheng Li, Xiaogang Wang, Xiaokang Yang, Cross-scene Crowd Counting via Deep Convolutional Neural Networks, CVPR, 2015.</li>
</ul></li>
<li>3D Shape Retrieval <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Wang_Sketch-Based_3D_Shape_2015_CVPR_paper.pdf">[Paper]</a>

<ul>
<li>Fang Wang, Le Kang, Yi Li, Sketch-based 3D Shape Retrieval using Convolutional Neural Networks, CVPR, 2015.</li>
</ul></li>
<li>Generate image <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Dosovitskiy_Learning_to_Generate_2015_CVPR_paper.pdf">[Paper]</a>

<ul>
<li>Alexey Dosovitskiy, Jost Tobias Springenberg, Thomas Brox, Learning to Generate Chairs with Convolutional Neural Networks, CVPR, 2015.</li>
</ul></li>
</ul>

<h2><a id="user-content-courses" class="anchor" href="#courses" aria-hidden="true"><span class="octicon octicon-link"></span></a>Courses</h2>

<ul>
<li>Deep Vision

<ul>
<li>[Stanford] <a href="http://cs231n.stanford.edu/">CS231n: Convolutional Neural Networks for Visual Recognition</a></li>
<li>[CUHK] <a href="https://piazza.com/cuhk.edu.hk/spring2015/eleg5040/home">ELEG 5040: Advanced Topics in Signal Processing(Introduction to Deep Learning)</a></li>
</ul></li>
<li>More Deep Learning

<ul>
<li>[Stanford] <a href="http://cs224d.stanford.edu/">CS224d: Deep Learning for Natural Language Processing</a></li>
<li>[Oxford] <a href="https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/">Deep Learning by Prof. Nando de Freitas</a></li>
<li>[NYU] <a href="http://cilvr.cs.nyu.edu/doku.php?id=courses:deeplearning2014:start">Deep Learning by Prof. Yann LeCun</a></li>
</ul></li>
</ul>

<h2><a id="user-content-books" class="anchor" href="#books" aria-hidden="true"><span class="octicon octicon-link"></span></a>Books</h2>

<ul>
<li>Free Online Books

<ul>
<li><a href="http://www.iro.umontreal.ca/%7Ebengioy/dlbook/">Deep Learning by Yoshua Bengio, Ian Goodfellow and Aaron Courville</a></li>
<li><a href="http://neuralnetworksanddeeplearning.com/">Neural Networks and Deep Learning by Michael Nielsen</a></li>
<li><a href="http://deeplearning.net/tutorial/deeplearning.pdf">Deep Learning Tutorial by LISA lab, University of Montreal</a></li>
</ul></li>
</ul>

<h2><a id="user-content-videos" class="anchor" href="#videos" aria-hidden="true"><span class="octicon octicon-link"></span></a>Videos</h2>

<ul>
<li>Talks

<ul>
<li><a href="https://www.youtube.com/watch?v=n1ViNeWhC24">Deep Learning, Self-Taught Learning and Unsupervised Feature Learning By Andrew Ng</a></li>
<li> <a href="https://www.youtube.com/watch?v=sc-KbuZqGkI">Recent Developments in Deep Learning By Geoff Hinton</a></li>
<li> <a href="https://www.youtube.com/watch?v=sc-KbuZqGkI">The Unreasonable Effectiveness of Deep Learning by Yann LeCun</a></li>
<li><a href="https://www.youtube.com/watch?v=4xsVFLnHC_0">Deep Learning of Representations by Yoshua bengio</a></li>
</ul></li>
<li>Courses

<ul>
<li><a href="http://www.computervisiontalks.com/tag/deep-learning-course/">Deep Learning Course – Nando de Freitas@Oxford</a></li>
</ul></li>
</ul>

<h2><a id="user-content-software" class="anchor" href="#software" aria-hidden="true"><span class="octicon octicon-link"></span></a>Software</h2>

<h3><a id="user-content-framework" class="anchor" href="#framework" aria-hidden="true"><span class="octicon octicon-link"></span></a>Framework</h3>

<ul>
<li>Torch7: Deep learning library in Lua, used by Facebook and Google Deepmind <a href="http://torch.ch/">[Web]</a></li>
<li>Caffe: Deep learning framework by the BVLC <a href="http://caffe.berkeleyvision.org/">[Web]</a></li>
<li>Theano: Mathematical library in Python, maintained by LISA lab <a href="http://deeplearning.net/software/theano/">[Web]</a>

<ul>
<li>Theano-based deep learning libraries: <a href="http://deeplearning.net/software/pylearn2/">Pylearn2</a>, <a href="https://github.com/mila-udem/blocks">Blocks</a>, <a href="http://keras.io/">Keras</a>, <a href="https://github.com/Lasagne/Lasagne">Lasagne</a></li>
</ul></li>
<li>MatConvNet: CNNs for MATLAB <a href="http://www.vlfeat.org/matconvnet/">[Web]</a></li>
</ul>

<h3><a id="user-content-applications" class="anchor" href="#applications" aria-hidden="true"><span class="octicon octicon-link"></span></a>Applications</h3>

<ul>
<li>Adversarial Training 

<ul>
<li>Code and hyperparameters for the paper "Generative Adversarial Networks" <a href="https://github.com/goodfeli/adversarial">[Web]</a></li>
</ul></li>
<li>Understanding and Visualizing

<ul>
<li>Source code for "Understanding Deep Image Representations by Inverting Them," CVPR, 2015. <a href="https://github.com/aravindhm/deep-goggle">[Web]</a></li>
</ul></li>
<li>Semantic Segmentation

<ul>
<li>Source code for the paper "Rich feature hierarchies for accurate object detection and semantic segmentation," CVPR, 2014. <a href="https://github.com/rbgirshick/rcnn">[Web]</a></li>
<li>Source code for the paper "Fully Convolutional Networks for Semantic Segmentation," CVPR, 2015. <a href="https://github.com/longjon/caffe/tree/future">[Web]</a></li>
</ul></li>
<li>Super-Resolution

<ul>
<li>Image Super-Resolution for Anime-Style-Art <a href="https://github.com/nagadomi/waifu2x">[Web]</a></li>
</ul></li>
<li>Edge Detection

<ul>
<li>Source code for the paper "DeepContour: A Deep Convolutional Feature Learned by Positive-Sharing Loss for Contour Detection," CVPR, 2015. <a href="https://github.com/shenwei1231/DeepContour">[Web]</a></li>
</ul></li>
</ul>

<h2><a id="user-content-tutorials" class="anchor" href="#tutorials" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tutorials</h2>

<ul>
<li>[CVPR 2014] <a href="https://sites.google.com/site/deeplearningcvpr2014/">Tutorial on Deep Learning in Computer Vision</a></li>
<li>[CVPR 2015] <a href="http://torch.ch/docs/cvpr15.html">Applied Deep Learning for Computer Vision with Torch</a></li>
</ul>

<h2><a id="user-content-blogs" class="anchor" href="#blogs" aria-hidden="true"><span class="octicon octicon-link"></span></a>Blogs</h2>

<ul>
<li><a href="http://www.computervisionblog.com/2015/06/deep-down-rabbit-hole-cvpr-2015-and.html">Deep down the rabbit hole: CVPR 2015 and beyond@Tombone's Computer Vision Blog</a></li>
<li><a href="http://zoyathinks.blogspot.kr/2015/06/cvpr-recap-and-where-were-going.html">CVPR recap and where we're going@Zoya Bylinskii (MIT PhD Student)'s Blog</a></li>
<li><a href="http://www.wired.com/2015/06/facebook-googles-fake-brains-spawn-new-visual-reality/">Facebook's AI Painting@Wired</a></li>
<li><a href="http://googleresearch.blogspot.kr/2015/06/inceptionism-going-deeper-into-neural.html">Inceptionism: Going Deeper into Neural Networks@Google Research</a></li>
</ul>
</article>
  </div>

</div>

<a href="#jump-to-line" rel="facebox[.linejump]" data-hotkey="l" style="display:none">Jump to Line</a>
<div id="jump-to-line" style="display:none">
  <!-- </textarea> --><!-- '"` --><form accept-charset="UTF-8" action="" class="js-jump-to-line-form" method="get"><div style="margin:0;padding:0;display:inline"><input name="utf8" type="hidden" value="&#x2713;" /></div>
    <input class="linejump-input js-jump-to-line-field" type="text" placeholder="Jump to line&hellip;" aria-label="Jump to line" autofocus>
    <button type="submit" class="btn">Go</button>
</form></div>

        </div>
      </div>
      <div class="modal-backdrop"></div>
    </div>
  </div>


    </div><!-- /.wrapper -->

      <div class="container">
  <div class="site-footer" role="contentinfo">
    <ul class="site-footer-links right">
        <li><a href="https://status.github.com/" data-ga-click="Footer, go to status, text:status">Status</a></li>
      <li><a href="https://developer.github.com" data-ga-click="Footer, go to api, text:api">API</a></li>
      <li><a href="https://training.github.com" data-ga-click="Footer, go to training, text:training">Training</a></li>
      <li><a href="https://shop.github.com" data-ga-click="Footer, go to shop, text:shop">Shop</a></li>
        <li><a href="https://github.com/blog" data-ga-click="Footer, go to blog, text:blog">Blog</a></li>
        <li><a href="https://github.com/about" data-ga-click="Footer, go to about, text:about">About</a></li>
        <li><a href="https://github.com/pricing" data-ga-click="Footer, go to pricing, text:pricing">Pricing</a></li>

    </ul>

    <a href="https://github.com" aria-label="Homepage">
      <span class="mega-octicon octicon-mark-github" title="GitHub"></span>
</a>
    <ul class="site-footer-links">
      <li>&copy; 2015 <span title="0.07389s from github-fe137-cp1-prd.iad.github.net">GitHub</span>, Inc.</li>
        <li><a href="https://github.com/site/terms" data-ga-click="Footer, go to terms, text:terms">Terms</a></li>
        <li><a href="https://github.com/site/privacy" data-ga-click="Footer, go to privacy, text:privacy">Privacy</a></li>
        <li><a href="https://github.com/security" data-ga-click="Footer, go to security, text:security">Security</a></li>
        <li><a href="https://github.com/contact" data-ga-click="Footer, go to contact, text:contact">Contact</a></li>
        <li><a href="https://help.github.com" data-ga-click="Footer, go to help, text:help">Help</a></li>
    </ul>
  </div>
</div>


    <div class="fullscreen-overlay js-fullscreen-overlay" id="fullscreen_overlay">
  <div class="fullscreen-container js-suggester-container">
    <div class="textarea-wrap">
      <textarea name="fullscreen-contents" id="fullscreen-contents" class="fullscreen-contents js-fullscreen-contents" placeholder="" aria-label=""></textarea>
      <div class="suggester-container">
        <div class="suggester fullscreen-suggester js-suggester js-navigation-container"></div>
      </div>
    </div>
  </div>
  <div class="fullscreen-sidebar">
    <a href="#" class="exit-fullscreen js-exit-fullscreen tooltipped tooltipped-w" aria-label="Exit Zen Mode">
      <span class="mega-octicon octicon-screen-normal"></span>
    </a>
    <a href="#" class="theme-switcher js-theme-switcher tooltipped tooltipped-w"
      aria-label="Switch themes">
      <span class="octicon octicon-color-mode"></span>
    </a>
  </div>
</div>



    
    

    <div id="ajax-error-message" class="flash flash-error">
      <span class="octicon octicon-alert"></span>
      <a href="#" class="octicon octicon-x flash-close js-ajax-error-dismiss" aria-label="Dismiss error"></a>
      Something went wrong with that request. Please try again.
    </div>


      <script crossorigin="anonymous" src="https://assets-cdn.github.com/assets/frameworks-2317046bbda4f1c516c598a8b2c63343669922648e6987a1ed4f909dce1fb689.js"></script>
      <script async="async" crossorigin="anonymous" src="https://assets-cdn.github.com/assets/github/index-f8dc41a3c9751e5dc0a90925d8355a1df17d95e0cff79e19938868ba28fccdfb.js"></script>
      
      
    <div class="js-stale-session-flash stale-session-flash flash flash-warn flash-banner hidden">
      <span class="octicon octicon-alert"></span>
      <span class="signed-in-tab-flash">You signed in with another tab or window. <a href="">Reload</a> to refresh your session.</span>
      <span class="signed-out-tab-flash">You signed out in another tab or window. <a href="">Reload</a> to refresh your session.</span>
    </div>
  </body>
</html>

# Deep-Learning
# Deep-Learning
